{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GoogLeNet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"4z3Ixzr4tqnp","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip3 install torch==0.4.0\n","!pip3 install torchvision==0.2.1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eNZd6eWBtg41","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import os\n","import argparse\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ovmjyS_JtxKF","colab_type":"code","colab":{}},"cell_type":"code","source":["parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n","parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n","parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n","args = parser.parse_args([])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6CAOx_adtyFt","colab_type":"code","colab":{}},"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","best_acc = 0  # best test accuracy\n","start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SJSveznQuccB","colab_type":"code","colab":{}},"cell_type":"code","source":["class Inception(nn.Module):\n","    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n","        super(Inception, self).__init__()\n","        # 1x1 conv branch\n","        self.b1 = nn.Sequential(\n","            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n","            nn.BatchNorm2d(n1x1),\n","            nn.ReLU(True),\n","        )\n","\n","        # 1x1 conv -> 3x3 conv branch\n","        self.b2 = nn.Sequential(\n","            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n","            nn.BatchNorm2d(n3x3red),\n","            nn.ReLU(True),\n","            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(n3x3),\n","            nn.ReLU(True),\n","        )\n","\n","        # 1x1 conv -> 5x5 conv branch\n","        self.b3 = nn.Sequential(\n","            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n","            nn.BatchNorm2d(n5x5red),\n","            nn.ReLU(True),\n","            nn.Conv2d(n5x5red, n5x5, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(n5x5),\n","            nn.ReLU(True),\n","            nn.Conv2d(n5x5, n5x5, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(n5x5),\n","            nn.ReLU(True),\n","        )\n","\n","        # 3x3 pool -> 1x1 conv branch\n","        self.b4 = nn.Sequential(\n","            nn.MaxPool2d(3, stride=1, padding=1),\n","            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n","            nn.BatchNorm2d(pool_planes),\n","            nn.ReLU(True),\n","        )\n","\n","    def forward(self, x):\n","        y1 = self.b1(x)\n","        y2 = self.b2(x)\n","        y3 = self.b3(x)\n","        y4 = self.b4(x)\n","        return torch.cat([y1,y2,y3,y4], 1)\n","\n","\n","class GoogLeNet(nn.Module):\n","    def __init__(self):\n","        super(GoogLeNet, self).__init__()\n","        self.pre_layers = nn.Sequential(\n","            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(192),\n","            nn.ReLU(True),\n","        )\n","\n","        self.a3 = Inception(192,  64,  96, 128, 16, 32, 32)\n","        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n","\n","        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n","\n","        self.a4 = Inception(480, 192,  96, 208, 16,  48,  64)\n","        self.b4 = Inception(512, 160, 112, 224, 24,  64,  64)\n","        self.c4 = Inception(512, 128, 128, 256, 24,  64,  64)\n","        self.d4 = Inception(512, 112, 144, 288, 32,  64,  64)\n","        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n","\n","        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n","        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n","\n","        self.avgpool = nn.AvgPool2d(8, stride=1)\n","        self.linear = nn.Linear(1024, 10)\n","\n","    def forward(self, x):\n","        out = self.pre_layers(x)\n","        out = self.a3(out)\n","        out = self.b3(out)\n","        out = self.maxpool(out)\n","        out = self.a4(out)\n","        out = self.b4(out)\n","        out = self.c4(out)\n","        out = self.d4(out)\n","        out = self.e4(out)\n","        out = self.maxpool(out)\n","        out = self.a5(out)\n","        out = self.b5(out)\n","        out = self.avgpool(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KAQjUrG3tzeW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1415},"outputId":"b0475709-c8e4-4728-ec6a-3f262eae3d2c","executionInfo":{"status":"error","timestamp":1534081566372,"user_tz":-540,"elapsed":270098,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["# Data\n","print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","# Model\n","print('==> Building model..')\n","# net = VGG('VGG19')\n","# net = ResNet18()\n","# net = PreActResNet18()\n","net = GoogLeNet()\n","# net = DenseNet121()\n","# net = ResNeXt29_2x64d()\n","# net = MobileNet()\n","# net = MobileNetV2()\n","# net = DPN92()\n","# net = ShuffleNetG2()\n","# net = SENet18()\n","net = net.to(device)\n","if device == 'cuda':\n","    net = torch.nn.DataParallel(net)\n","    cudnn.benchmark = True\n","\n","if args.resume:\n","    # Load checkpoint.\n","    print('==> Resuming from checkpoint..')\n","    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n","    checkpoint = torch.load('./checkpoint/ckpt.t7')\n","    net.load_state_dict(checkpoint['net'])\n","    best_acc = checkpoint['acc']\n","    start_epoch = checkpoint['epoch']\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n","\n","# Training\n","def train(epoch):\n","    print('\\nEpoch: %d' % epoch)\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","    print('訓練：Loss: %.3f | Acc: %.3f%%'\n","          % (train_loss/total, 100.*correct/total))\n","\n","def test(epoch):\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","        print('テスト：Loss: %.3f | Acc: %.3f%%'\n","            % (test_loss/(batch_idx+1), 100.*correct/total))\n","\n","    # Save checkpoint.\n","    acc = 100.*correct/total\n","    if acc > best_acc:\n","        print('Saving..')\n","        state = {\n","            'net': net.state_dict(),\n","            'acc': acc,\n","            'epoch': epoch,\n","        }\n","        if not os.path.isdir('checkpoint'):\n","            os.mkdir('checkpoint')\n","        torch.save(state, './checkpoint/ckpt.t7')\n","        best_acc = acc\n","\n","\n","for epoch in range(start_epoch, start_epoch+2):\n","    train(epoch)\n","    test(epoch)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n","==> Building model..\n","\n","Epoch: 0\n"],"name":"stdout"},{"output_type":"stream","text":["Process Process-2:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","Process Process-1:\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n","    r = index_queue.get()\n","  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n","    res = self._reader.recv_bytes()\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","Traceback (most recent call last):\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n","    r = index_queue.get()\n","  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n","    res = self._reader.recv_bytes()\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fc5761b03c8>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 347, in __del__\n","    def __del__(self):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 178, in handler\n","    _error_if_any_worker_fails()\n","RuntimeError: DataLoader worker (pid 490) exited unexpectedly with exit code 1.\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f24a65cd3a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-f24a65cd3a34>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"aiZGPWLIufrg","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}